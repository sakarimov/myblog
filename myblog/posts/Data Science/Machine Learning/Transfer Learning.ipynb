{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee7661be-242b-4c62-a973-0ec9a148767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "# initialize the path to the *original* input directory of images\n",
    "ORIG_INPUT_DATASET = \"Food-5K\"\n",
    "# initialize the base path to the *new* directory that will contain\n",
    "# our images after computing the training and testing split\n",
    "BASE_PATH = \"datasets/images/rps\"\n",
    "# define the names of the training, testing, and validation\n",
    "# directories\n",
    "TRAIN = \"train\"\n",
    "TEST = \"val\"\n",
    "# initialize the list of class label names\n",
    "CLASSES = [\"rock\", \"paper\", \"scissors\"]\n",
    "# set the batch size\n",
    "BATCH_SIZE = 4\n",
    "# initialize the label encoder file path and the output directory to\n",
    "# where the extracted features (in CSV file format) will be stored\n",
    "LE_PATH = os.path.sep.join([\"rpsoutput\", \"le.cpickle\"])\n",
    "BASE_CSV_PATH = \"rpsoutput\"\n",
    "# set the path to the serialized model after training\n",
    "MODEL_PATH = os.path.sep.join([\"rpsoutput\", \"model.cpickle\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c746c6fc-a244-4931-b759-9e46d7078b7c",
   "metadata": {},
   "source": [
    "# import the necessary packages\n",
    "from pyimagesearch import config\n",
    "from imutils import paths\n",
    "import shutil\n",
    "import os\n",
    "# loop over the data splits\n",
    "for split in (config.TRAIN, config.TEST, config.VAL):\n",
    "\t# grab all image paths in the current split\n",
    "\tprint(\"[INFO] processing '{} split'...\".format(split))\n",
    "\tp = os.path.sep.join([config.ORIG_INPUT_DATASET, split])\n",
    "\timagePaths = list(paths.list_images(p))\n",
    "    \t# loop over the image paths\n",
    "\tfor imagePath in imagePaths:\n",
    "\t\t# extract class label from the filename\n",
    "\t\tfilename = imagePath.split(os.path.sep)[-1]\n",
    "\t\tlabel = config.CLASSES[int(filename.split(\"_\")[0])]\n",
    "\t\t# construct the path to the output directory\n",
    "\t\tdirPath = os.path.sep.join([config.BASE_PATH, split, label])\n",
    "\t\t# if the output directory does not exist, create it\n",
    "\t\tif not os.path.exists(dirPath):\n",
    "\t\t\tos.makedirs(dirPath)\n",
    "\t\t# construct the path to the output image file and copy it\n",
    "\t\tp = os.path.sep.join([dirPath, filename])\n",
    "\t\tshutil.copy2(imagePath, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81028874-5a2b-4854-a70d-45d4e96d3c56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 13:09:00.027397: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 13:09:01.839505: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-12 13:09:01.847179: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-12 13:09:01.847420: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-12 13:09:01.848740: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-12 13:09:01.848957: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-12 13:09:01.849144: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-12 13:09:01.893914: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-12 13:09:01.894166: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-12 13:09:01.894367: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-12 13:09:01.894523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3503 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing 'train split'...\n",
      "[INFO] processing batch 1/328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1718197742.641173      90 service.cc:145] XLA service 0x7871e8004be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1718197742.641208      90 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 960M, Compute Capability 5.0\n",
      "2024-06-12 13:09:02.653166: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-12 13:09:02.746601: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1718197749.379902      90 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processing batch 2/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "[INFO] processing batch 3/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "[INFO] processing batch 4/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "[INFO] processing batch 5/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "[INFO] processing batch 6/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "[INFO] processing batch 7/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "[INFO] processing batch 8/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "[INFO] processing batch 9/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "[INFO] processing batch 10/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "[INFO] processing batch 11/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "[INFO] processing batch 12/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[INFO] processing batch 13/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[INFO] processing batch 14/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "[INFO] processing batch 15/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "[INFO] processing batch 16/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "[INFO] processing batch 17/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "[INFO] processing batch 18/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "[INFO] processing batch 19/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[INFO] processing batch 20/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "[INFO] processing batch 21/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "[INFO] processing batch 22/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "[INFO] processing batch 23/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "[INFO] processing batch 24/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "[INFO] processing batch 25/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "[INFO] processing batch 26/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "[INFO] processing batch 27/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "[INFO] processing batch 28/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "[INFO] processing batch 29/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "[INFO] processing batch 30/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "[INFO] processing batch 31/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "[INFO] processing batch 32/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "[INFO] processing batch 33/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "[INFO] processing batch 34/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "[INFO] processing batch 35/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "[INFO] processing batch 36/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "[INFO] processing batch 37/328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "[INFO] processing batch 38/328\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;66;03m# loop over the images and labels in the current batch\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \t\t\u001b[38;5;28;01mfor\u001b[39;00m imagePath \u001b[38;5;129;01min\u001b[39;00m batchPaths:\n\u001b[1;32m     46\u001b[0m \t\t\t\u001b[38;5;66;03m# load the input image using the Keras helper utility\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \t\t\t\u001b[38;5;66;03m# while ensuring the image is resized to 224x224 pixels\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \t\t\timage \u001b[38;5;241m=\u001b[39m \u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagePath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \t\t\timage \u001b[38;5;241m=\u001b[39m img_to_array(image)\n\u001b[1;32m     50\u001b[0m \t\t\t\u001b[38;5;66;03m# preprocess the image by (1) expanding the dimensions and\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \t\t\t\u001b[38;5;66;03m# (2) subtracting the mean RGB pixel intensity from the\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \t\t\t\u001b[38;5;66;03m# ImageNet dataset\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/image_utils.py:292\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    290\u001b[0m             img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mresize(width_height_tuple, resample, box\u001b[38;5;241m=\u001b[39mcrop_box)\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 292\u001b[0m             img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth_height_tuple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py:2164\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   2162\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(size)\n\u001b[0;32m-> 2164\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2166\u001b[0m     box \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "# load the VGG16 network and initialize the label encoder\n",
    "print(\"[INFO] loading network...\")\n",
    "model = VGG16(weights=\"imagenet\", include_top=False)\n",
    "le = None\n",
    "# loop over the data splits\n",
    "for split in (TRAIN, TEST):\n",
    "\t# grab all image paths in the current split\n",
    "\tprint(\"[INFO] processing '{} split'...\".format(split))\n",
    "\tp = os.path.sep.join([BASE_PATH, split])\n",
    "\timagePaths = list(paths.list_images(p))\n",
    "\t# randomly shuffle the image paths and then extract the class\n",
    "\t# labels from the file paths\n",
    "\t#random.shuffle(imagePaths)\n",
    "\tlabels = [p.split(os.path.sep)[-2] for p in imagePaths]\n",
    "\t# if the label encoder is None, create it\n",
    "\tif le is None:\n",
    "\t\tle = LabelEncoder()\n",
    "\t\tle.fit(labels)\n",
    "\t# open the output CSV file for writing\n",
    "\tcsvPath = os.path.sep.join([BASE_CSV_PATH,\n",
    "\t\t\"{}.csv\".format(split)])\n",
    "\tcsv = open(csvPath, \"w\")\n",
    "    # loop over the images in batches\n",
    "\tfor (b, i) in enumerate(range(0, len(imagePaths), BATCH_SIZE)):\n",
    "\t\t# extract the batch of images and labels, then initialize the\n",
    "\t\t# list of actual images that will be passed through the network\n",
    "\t\t# for feature extraction\n",
    "\t\tprint(\"[INFO] processing batch {}/{}\".format(b + 1,\n",
    "\t\t\tint(np.ceil(len(imagePaths) / float(BATCH_SIZE)))))\n",
    "\t\tbatchPaths = imagePaths[i:i + BATCH_SIZE]\n",
    "\t\tbatchLabels = le.transform(labels[i:i + BATCH_SIZE])\n",
    "\t\tbatchImages = []\n",
    "        # loop over the images and labels in the current batch\n",
    "\t\tfor imagePath in batchPaths:\n",
    "\t\t\t# load the input image using the Keras helper utility\n",
    "\t\t\t# while ensuring the image is resized to 224x224 pixels\n",
    "\t\t\timage = load_img(imagePath, target_size=(224, 224))\n",
    "\t\t\timage = img_to_array(image)\n",
    "\t\t\t# preprocess the image by (1) expanding the dimensions and\n",
    "\t\t\t# (2) subtracting the mean RGB pixel intensity from the\n",
    "\t\t\t# ImageNet dataset\n",
    "\t\t\timage = np.expand_dims(image, axis=0)\n",
    "\t\t\timage = preprocess_input(image)\n",
    "\t\t\t# add the image to the batch\n",
    "\t\t\tbatchImages.append(image)\n",
    "        # pass the images through the network and use the outputs as\n",
    "\t\t# our actual features, then reshape the features into a\n",
    "\t\t# flattened volume\n",
    "\t\tbatchImages = np.vstack(batchImages)\n",
    "\t\tfeatures = model.predict(batchImages, batch_size=BATCH_SIZE)\n",
    "\t\tfeatures = features.reshape((features.shape[0], 7 * 7 * 512))\n",
    "        # loop over the class labels and extracted features\n",
    "\t\tfor (label, vec) in zip(batchLabels, features):\n",
    "\t\t\t# construct a row that exists of the class label and\n",
    "\t\t\t# extracted features\n",
    "\t\t\tvec = \",\".join([str(v) for v in vec])\n",
    "\t\t\tcsv.write(\"{},{}\\n\".format(label, vec))\n",
    "\t# close the CSV file csv.close() # serialize the label encoder to disk f = open(LE_PATH, \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208fb465-6b4f-494b-a371-b7bd0a8f2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "def load_data_split(splitPath):\n",
    "\t# initialize the data and labels\n",
    "\tdata = []\n",
    "\tlabels = []\n",
    "\t# loop over the rows in the data split file\n",
    "\tfor row in open(splitPath):\n",
    "\t\t# extract the class label and features from the row\n",
    "\t\trow = row.strip().split(\",\")\n",
    "\t\tlabel = row[0]\n",
    "\t\tfeatures = np.array(row[1:], dtype=\"float\")\n",
    "\t\t# update the data and label lists\n",
    "\t\tdata.append(features)\n",
    "\t\tlabels.append(label)\n",
    "\t# convert the data and labels to NumPy arrays\n",
    "\tdata = np.array(data)\n",
    "\tlabels = np.array(labels)\n",
    "\t# return a tuple of the data and labels\n",
    "\treturn (data, labels)\n",
    "\n",
    "# derive the paths to the training and testing CSV files\n",
    "trainingPath = os.path.sep.join([BASE_CSV_PATH,\n",
    "\t\"{}.csv\".format(TRAIN)])\n",
    "testingPath = os.path.sep.join([BASE_CSV_PATH,\n",
    "\t\"{}.csv\".format(TEST)])\n",
    "# load the data from disk\n",
    "print(\"[INFO] loading data...\")\n",
    "(trainX, trainY) = load_data_split(trainingPath)\n",
    "print(trainX.shape)\n",
    "(testX, testY) = load_data_split(testingPath)\n",
    "# load the label encoder from disk\n",
    "le = pickle.loads(open(LE_PATH, \"rb\").read())\n",
    "\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "print(testX)\n",
    "modelLogReg = LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\",\n",
    "\tmax_iter=150)\n",
    "modelLogReg.fit(trainX, trainY)\n",
    "# evaluate the model\n",
    "print(\"[INFO] evaluating...\")\n",
    "preds = modelLogReg.predict(testX)\n",
    "print(classification_report(testY, preds, target_names=le.classes_))\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving model...\")\n",
    "f = open(MODEL_PATH, \"wb\")\n",
    "f.write(pickle.dumps(modelLogReg))\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643fb4b-2de2-458f-83c3-837145b07772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#from google.colab import files\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "testdir = 'datasets/images/rps/test/'\n",
    "uploaded = os.listdir(testdir)\n",
    "fig = plt.figure(figsize= (10, 10))\n",
    "#fig.tight_layout(pad=5.0)\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "for i in range(len(uploaded)):\n",
    "    path = testdir + uploaded[i]\n",
    "    img = image.load_img(path, target_size = (224,224))\n",
    "\n",
    "    ax = fig.add_subplot(4, 4, i+1)\n",
    "    ax.imshow(img)\n",
    "    images = img_to_array(img)\n",
    "    images = np.expand_dims(images, axis=0)\n",
    "    images = preprocess_input(images)\n",
    "    #images = np.vstack([x])\n",
    "    features = model.predict(images, batch_size=BATCH_SIZE)\n",
    "    features = features.reshape((features.shape[0], 7 * 7 * 512))\n",
    "    pred = modelLogReg.predict(features)\n",
    "    ax.title.set_text(le.classes_[int(pred[0])])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
